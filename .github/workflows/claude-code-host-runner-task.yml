name: Claude Code Host Runner Task

on:
  workflow_dispatch:
    inputs:
      task_description:
        description: "Task for Claude Code to implement (leave blank for default self-improvement task)"
        required: false
        default: ""
      strategy:
        description: "Execution strategy"
        required: false
        default: "strong-cheap-strong"
        type: choice
        options:
          - strong-cheap-strong
          - cheap-only
          - strong-only

jobs:
  claude-code-task:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.13"

      - name: Set up Node.js (for Claude Code CLI)
        uses: actions/setup-node@v4
        with:
          node-version: "22"

      - name: Install Claude Code CLI
        run: npm install -g @anthropic-ai/claude-code

      - name: Verify claude CLI and auth
        run: |
          which claude
          claude --version
          CLAUDECODE= claude auth status --json

      - name: Install API dependencies
        run: cd api && pip install -e ".[dev]"

      # -----------------------------------------------------------------------
      # PHASE 1 — STRONG (Opus): Assess, plan, and reason about the task
      # Uses claude-opus-4-5 for deep analysis. Outputs a plan.json with:
      #   - problem statement
      #   - files to change
      #   - implementation steps
      #   - acceptance criteria
      # -----------------------------------------------------------------------
      - name: "Phase 1 — STRONG (Opus): Assess and plan"
        id: phase1_plan
        if: ${{ inputs.strategy != 'cheap-only' }}
        run: |
          echo "=== PHASE 1: STRONG ASSESSMENT (claude-opus-4-5) ==="

          cat > /tmp/phase1_task.txt << 'PHASE1EOF'
          You are an expert software architect performing a pre-implementation assessment.

          Your job is to analyze the following task and produce a precise implementation plan.

          TASK:
          Improve the Claude provider snapshot in api/app/services/automation_usage_service.py.

          Context from live API discovery:
          - The current _build_claude_snapshot() hits /v1/models to get rate limits — but no rate limit headers are returned from that endpoint.
          - The Anthropic messages API (/v1/messages) DOES return rate limit headers:
              anthropic-ratelimit-requests-limit, anthropic-ratelimit-requests-remaining
              anthropic-ratelimit-input-tokens-limit, anthropic-ratelimit-input-tokens-remaining
              anthropic-ratelimit-output-tokens-limit, anthropic-ratelimit-output-tokens-remaining
              anthropic-ratelimit-tokens-limit, anthropic-ratelimit-tokens-remaining
          - The current _probe_claude() only checks the models URL — it never gets real quota headers.
          - Claude Code CLI (claude -p --output-format json) returns a `modelUsage` dict showing
            per-model token counts and cost_usd — this is the actual usage data we need.

          Also improve api/app/services/agent_routing_service.py:
          - The `claude` executor currently falls through to ROUTING[task_type] which returns `openrouter/free`
          - A CLAUDE_CODE_MODEL_BY_TYPE dict should define:
              SPEC/TEST/IMPL → claude-sonnet-4-5-20250929  (cheap, fast, good at code)
              REVIEW/HEAL   → claude-opus-4-5             (strong, thorough review)
          - route_for_executor() should use CLAUDE_CODE_MODEL_BY_TYPE when executor == "claude"
          - The command template should be:
              claude -p "{{direction}}" --model {model} --dangerously-skip-permissions --output-format json
            so we can capture the modelUsage JSON output for cost/token tracking.

          YOUR OUTPUT:
          1. Read the relevant code sections in both files.
          2. Output a precise plan as a JSON object to /tmp/plan.json with:
             {
               "problem": "...",
               "files": ["path/to/file1.py", ...],
               "changes": [
                 {"file": "...", "what": "...", "why": "..."},
                 ...
               ],
               "acceptance_criteria": ["...", "..."],
               "risks": ["..."]
             }
          3. Also print the plan to stdout so it appears in CI logs.
          4. Do NOT make any code changes — assessment only.
          PHASE1EOF

          claude -p "$(cat /tmp/phase1_task.txt)" \
            --model claude-opus-4-5 \
            --dangerously-skip-permissions \
            --output-format json 2>/tmp/phase1_raw.json

          # Extract text result and usage
          python3 << 'PYEOF'
          import json, sys
          with open('/tmp/phase1_raw.json') as f:
              d = json.load(f)
          print("=== PHASE 1 RESULT ===")
          print(d.get('result', '(no result)'))
          usage = d.get('modelUsage', {})
          for model, stats in usage.items():
              print(f"\n[USAGE] model={model}")
              print(f"  inputTokens={stats.get('inputTokens')} outputTokens={stats.get('outputTokens')}")
              print(f"  costUSD={stats.get('costUSD'):.6f}")
          print(f"\n[TOTAL] cost_usd={d.get('total_cost_usd'):.6f} duration_ms={d.get('duration_ms')}")
          PYEOF
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

      # -----------------------------------------------------------------------
      # PHASE 2 — CHEAP (Sonnet): Implement the plan
      # Uses claude-sonnet-4-5-20250929 for implementation.
      # Sonnet is 5x cheaper than Opus and fast at code changes.
      # -----------------------------------------------------------------------
      - name: "Phase 2 — CHEAP (Sonnet): Implement"
        id: phase2_impl
        run: |
          echo "=== PHASE 2: CHEAP IMPLEMENTATION (claude-sonnet-4-5-20250929) ==="

          STRATEGY="${{ inputs.strategy }}"
          DEFAULT_TASK="${{ inputs.task_description }}"

          if [ -n "$DEFAULT_TASK" ]; then
            echo "$DEFAULT_TASK" > /tmp/phase2_task.txt
          else
            cat > /tmp/phase2_task.txt << 'PHASE2EOF'
          You are a software engineer implementing a pre-approved plan.

          TASK — implement ALL of the following changes:

          === CHANGE 1: Fix _build_claude_snapshot() in api/app/services/automation_usage_service.py ===

          The function currently hits /v1/models for rate limits — no headers come back.
          Replace the models probe with a lightweight messages probe that gets real rate limit headers.

          Specifically, after confirming the API key exists, make a minimal POST to
          https://api.anthropic.com/v1/messages with model=claude-haiku-4-5 and max_tokens=1 to
          get the rate limit headers. Extract:
            - anthropic-ratelimit-requests-limit / anthropic-ratelimit-requests-remaining
            - anthropic-ratelimit-input-tokens-limit / anthropic-ratelimit-input-tokens-remaining
            - anthropic-ratelimit-output-tokens-limit / anthropic-ratelimit-output-tokens-remaining
          Also keep the models list call (for model visibility count) but don't depend on it for limits.

          The updated snapshot should show:
            - "Claude API requests quota" with limit/remaining/window="minute"
            - "Claude API input token quota" with limit/remaining/window="minute"
            - "Claude API output token quota" with limit/remaining/window="minute"
            - "Claude visible models" (existing)

          Also update _probe_claude() to use the messages probe (POST) and return
          "ok_cli_and_api_key" when both ANTHROPIC_API_KEY is set and messages probe succeeds.

          === CHANGE 2: Add CLAUDE_CODE_MODEL_BY_TYPE to api/app/services/agent_routing_service.py ===

          After the existing OPENCLAW_MODEL_BY_TYPE dict, add:

          _CLAUDE_CODE_MODEL_DEFAULT = os.environ.get("CLAUDE_CODE_MODEL", "claude-sonnet-4-5-20250929")
          _CLAUDE_CODE_MODEL_REVIEW = os.environ.get("CLAUDE_CODE_REVIEW_MODEL", "claude-opus-4-5")

          CLAUDE_CODE_MODEL_BY_TYPE: dict[TaskType, str] = {
              TaskType.SPEC: _CLAUDE_CODE_MODEL_DEFAULT,
              TaskType.TEST: _CLAUDE_CODE_MODEL_DEFAULT,
              TaskType.IMPL: _CLAUDE_CODE_MODEL_DEFAULT,
              TaskType.REVIEW: _CLAUDE_CODE_MODEL_REVIEW,
              TaskType.HEAL: _CLAUDE_CODE_MODEL_REVIEW,
          }

          Also update route_for_executor() so the `else` branch (claude executor) uses
          CLAUDE_CODE_MODEL_BY_TYPE[task_type] instead of ROUTING[task_type]:

          Before:
              else:
                  model, tier = ROUTING[task_type]
                  template = default_command_template

          After:
              else:
                  cc_model = CLAUDE_CODE_MODEL_BY_TYPE[task_type]
                  model = f"claude/{cc_model}"
                  tier = "claude"
                  template = f'claude -p "{{{{direction}}}}" --model {cc_model} --dangerously-skip-permissions --output-format json'

          Also update claude_command_template() (add this new function after openclaw_command_template):

          def claude_command_template(task_type: TaskType) -> str:
              model = CLAUDE_CODE_MODEL_BY_TYPE[task_type]
              return f'claude -p "{{{{direction}}}}" --model {model} --dangerously-skip-permissions --output-format json'

          Also update executor_binary_name() — the current code returns "aider" for claude executor.
          Change it to return "claude".

          === VALIDATION ===
          After making changes:
          1. Run: cd api && python3 -m pytest tests/ -x -q --tb=short 2>&1 | tail -10
          2. Show git diff --stat
          3. Do NOT commit.
          PHASE2EOF
          fi

          claude -p "$(cat /tmp/phase2_task.txt)" \
            --model claude-sonnet-4-5-20250929 \
            --dangerously-skip-permissions \
            --output-format json 2>/tmp/phase2_raw.json

          python3 << 'PYEOF'
          import json
          with open('/tmp/phase2_raw.json') as f:
              d = json.load(f)
          print("=== PHASE 2 RESULT ===")
          print(d.get('result', '(no result)'))
          usage = d.get('modelUsage', {})
          for model, stats in usage.items():
              print(f"\n[USAGE] model={model}")
              print(f"  inputTokens={stats.get('inputTokens')} outputTokens={stats.get('outputTokens')}")
              print(f"  cacheReadInputTokens={stats.get('cacheReadInputTokens')} cacheCreationInputTokens={stats.get('cacheCreationInputTokens')}")
              print(f"  costUSD={stats.get('costUSD'):.6f}")
          print(f"\n[TOTAL] cost_usd={d.get('total_cost_usd'):.6f} duration_ms={d.get('duration_ms')}")
          PYEOF
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}

      # -----------------------------------------------------------------------
      # PHASE 3 — STRONG (Opus/Sonnet): Review, verify, and compare
      # Uses claude-opus-4-5 to review the implementation and compare
      # Claude Code vs Codex execution on this task.
      # -----------------------------------------------------------------------
      - name: "Phase 3 — STRONG (Opus): Review and compare"
        id: phase3_review
        if: ${{ inputs.strategy != 'cheap-only' }}
        run: |
          echo "=== PHASE 3: STRONG REVIEW (claude-opus-4-5) ==="

          cat > /tmp/phase3_task.txt << 'PHASE3EOF'
          You are a senior engineer reviewing implemented changes and comparing executor performance.

          REVIEW TASKS:
          1. Run the full test suite: cd api && python3 -m pytest tests/ -x -q --tb=short 2>&1 | tail -15
          2. Show git diff of changed files.
          3. Verify the changes are correct:
             - Does _build_claude_snapshot() now use the messages endpoint for rate limits?
             - Does CLAUDE_CODE_MODEL_BY_TYPE exist in agent_routing_service.py?
             - Does route_for_executor() use it for the claude executor branch?
             - Does executor_binary_name() return "claude" for the claude executor?
          4. Report any issues found.
          5. Produce a comparison report between Claude Code (claude executor) and
             OpenAI Codex (openclaw/openai-codex executor) for implementation tasks:
             - Model tier mapping: what model does each use per task type?
             - Cost model: per-token pricing (Sonnet ~$3/Mtok in, Opus ~$15/Mtok in, Codex varies)
             - Usage limit visibility: which has better observability?
             - Strengths and weaknesses for: SPEC, TEST, IMPL, REVIEW, HEAL task types
             - Recommendation: when to prefer claude vs codex as executor
          PHASE3EOF

          claude -p "$(cat /tmp/phase3_task.txt)" \
            --model claude-opus-4-5 \
            --dangerously-skip-permissions \
            --output-format json 2>/tmp/phase3_raw.json

          python3 << 'PYEOF'
          import json
          with open('/tmp/phase3_raw.json') as f:
              d = json.load(f)
          print("=== PHASE 3 RESULT ===")
          print(d.get('result', '(no result)'))
          usage = d.get('modelUsage', {})
          for model, stats in usage.items():
              print(f"\n[USAGE] model={model}")
              print(f"  inputTokens={stats.get('inputTokens')} outputTokens={stats.get('outputTokens')}")
              print(f"  costUSD={stats.get('costUSD'):.6f}")
          print(f"\n[TOTAL] cost_usd={d.get('total_cost_usd'):.6f} duration_ms={d.get('duration_ms')}")
          PYEOF

      # -----------------------------------------------------------------------
      # SUMMARY — Aggregate cost and usage across all phases
      # -----------------------------------------------------------------------
      - name: "Summary: Aggregate usage across strong-cheap-strong phases"
        if: always()
        run: |
          python3 << 'PYEOF'
          import json, os, glob

          phase_files = {
              "phase1_opus_assess": "/tmp/phase1_raw.json",
              "phase2_sonnet_impl": "/tmp/phase2_raw.json",
              "phase3_opus_review": "/tmp/phase3_raw.json",
          }

          total_cost = 0.0
          total_input = 0
          total_output = 0
          model_totals = {}

          print("=" * 60)
          print("STRONG-CHEAP-STRONG USAGE SUMMARY")
          print("=" * 60)

          for phase, fpath in phase_files.items():
              if not os.path.exists(fpath):
                  print(f"\n{phase}: (skipped)")
                  continue
              with open(fpath) as f:
                  d = json.load(f)
              phase_cost = d.get('total_cost_usd', 0.0)
              total_cost += phase_cost
              usage = d.get('modelUsage', {})
              print(f"\n{phase}:")
              for model, stats in usage.items():
                  inp = stats.get('inputTokens', 0)
                  out = stats.get('outputTokens', 0)
                  cost = stats.get('costUSD', 0.0)
                  total_input += inp
                  total_output += out
                  if model not in model_totals:
                      model_totals[model] = {'inputTokens': 0, 'outputTokens': 0, 'costUSD': 0.0}
                  model_totals[model]['inputTokens'] += inp
                  model_totals[model]['outputTokens'] += out
                  model_totals[model]['costUSD'] += cost
                  print(f"  {model}: in={inp:,} out={out:,} cost=${cost:.4f}")

          print(f"\n{'=' * 60}")
          print("TOTALS BY MODEL:")
          for model, stats in model_totals.items():
              tier = "STRONG(opus)" if "opus" in model else "CHEAP(sonnet)" if "sonnet" in model else "CHEAP(haiku)"
              print(f"  [{tier}] {model}")
              print(f"    inputTokens={stats['inputTokens']:,} outputTokens={stats['outputTokens']:,} costUSD=${stats['costUSD']:.4f}")
          print(f"\nTOTAL COST: ${total_cost:.4f}")
          print(f"TOTAL TOKENS: {total_input + total_output:,} (in={total_input:,}, out={total_output:,})")
          print("=" * 60)
          PYEOF
